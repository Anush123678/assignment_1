{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anush123678/assignment_1/blob/main/spaceshiptatanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlEX4_OXZo73"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "import pandas as pd_spaceship\n",
        "import numpy as np_spaceship\n",
        "import seaborn as sns_spaceship\n",
        "import matplotlib.pyplot as plt_spaceship\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "# Load data\n",
        "train_df_spaceship = pd_spaceship.read_csv('/content/drive/MyDrive/train.csv')\n",
        "test_df_spaceship = pd_spaceship.read_csv('/content/drive/MyDrive/test.csv')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Display the first few rows of the training dataset to understand its structure\n",
        "train_df_spaceship.head()\n",
        "\n",
        "# Extract and store the 'PassengerId' column from the test dataset for submission purposes\n",
        "test_passenger_ids = test_df_spaceship['PassengerId']\n",
        "\n",
        "# Print the number of missing values for each column in the training dataset\n",
        "print(train_df_spaceship.isnull().sum())\n",
        "\n",
        "# Plot the distribution of the target variable 'Transported' to visualize the class balance\n",
        "sns_spaceship.countplot(data=train_df_spaceship, x='Transported', color='skyblue')\n",
        "plt_spaceship.show()\n",
        "\n",
        "# Create histograms for the numerical features to examine their distributions\n",
        "numeric_features = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
        "train_df_spaceship[numeric_features].hist(bins=15, figsize=(15, 10), color='skyblue', edgecolor='black')\n",
        "plt_spaceship.show()"
      ],
      "metadata": {
        "id": "mWxxE6csdqeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the 'PassengerId', 'Name', 'Cabin', and 'VIP' columns from both the training and test datasets to clean the data\n",
        "train_df_spaceship.drop(['PassengerId', 'Name', 'Cabin', 'VIP'], axis=1, inplace=True)\n",
        "test_df_spaceship.drop(['PassengerId', 'Name', 'Cabin', 'VIP'], axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "zQVGZ9s4dqgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the categorical and numerical features to be processed separately\n",
        "categorical_features_spaceship = ['HomePlanet', 'CryoSleep', 'Destination']\n",
        "numeric_features_spaceship = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
        "\n",
        "# Create imputers for filling missing values in numerical and categorical features\n",
        "numeric_imputer = SimpleImputer(strategy='median')\n",
        "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Fill missing values in numerical features using the median value of each column\n",
        "train_df_spaceship[numeric_features_spaceship] = numeric_imputer.fit_transform(train_df_spaceship[numeric_features_spaceship])\n",
        "test_df_spaceship[numeric_features_spaceship] = numeric_imputer.transform(test_df_spaceship[numeric_features_spaceship])"
      ],
      "metadata": {
        "id": "pev0mQIcdqjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values in categorical features using the most frequent value of each column\n",
        "train_df_spaceship[categorical_features_spaceship] = categorical_imputer.fit_transform(train_df_spaceship[categorical_features_spaceship])\n",
        "test_df_spaceship[categorical_features_spaceship] = categorical_imputer.transform(test_df_spaceship[categorical_features_spaceship])\n",
        "\n",
        "# Convert categorical variables into numerical values using LabelEncoder for model compatibility\n",
        "label_encoders = {}\n",
        "for feature in categorical_features_spaceship:\n",
        "    label_encoders[feature] = LabelEncoder()\n",
        "    train_df_spaceship[feature] = label_encoders[feature].fit_transform(train_df_spaceship[feature])\n",
        "    test_df_spaceship[feature] = label_encoders[feature].transform(test_df_spaceship[feature])"
      ],
      "metadata": {
        "id": "1dnVvVQRdql3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ll4644wBdqoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-cs6gdEldqpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_5F80bq_dqsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MB_qtRy0dquv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AxzwowEzdqxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "25UCoB37dqzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FPDT315Ddq18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_h2EK1JHdq4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W-aTlbNXdq6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GLX2CULIdq94"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}